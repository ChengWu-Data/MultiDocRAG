# ğŸ§  **MultiDocRAG**

### *A Retrieval-Augmented Multi-Document Reasoning Assistant*

MultiDocRAG is an LLM-powered system designed for **cross-document reasoning**.
It enables users to upload multiple PDFsâ€”papers, reports, articlesâ€”and ask grounded questions that require **comparison, synthesis, and multi-document understanding**.

The system integrates:

* **Multi-document ingestion & chunking**
* **Vector-based retrieval with embeddings**
* **LLM reasoning over retrieved evidence**
* **Optional conversational memory** for context continuity
* **A full evaluation pipeline** comparing baseline LLM vs RAG-enhanced performance

This project was developed as part of **COMS 4995 â€“ Applied Machine Learning** at Columbia.

---

## ğŸš€ **Key Features**

### **ğŸ“„ Multi-Document Ingestion**

Upload several PDFs at once.
The system automatically extracts text, segments it into semantic chunks, and stores them in a vector database.

### **ğŸ” Retrieval-Augmented Generation (RAG)**

Queries are grounded in the uploaded documents through top-k similarity search.
Responses include **citations** to the most relevant chunks.

### **ğŸ§© Cross-Document Reasoning**

Designed to answer questions like:

* *â€œCompare method A in Paper 1 and method B in Paper 2.â€*
* *â€œSummarize common limitations across these documents.â€*
* *â€œWhat does Paper 3 say about X, and how does it differ from Paper 1?â€*

### **ğŸ§  Optional Memory Module**

Keeps track of previous interactions and user preferences to improve coherence in multi-turn conversations.

### **ğŸ“Š Evaluation Framework**

We rigorously compare:

* **Baseline LLM** (no RAG, single-pass prompting)
* **RAG-based system**
* **RAG + Memory system**

Using metrics such as:

* Relevance
* Faithfulness
* Ability to cite correct documents
* Multi-document synthesis quality

### **ğŸ’» Clean Demo Interface**

A simple UI / notebook demo allows:

1. PDF upload
2. Query input
3. Retrieval visualization
4. Final synthesized answer with citations

---

## ğŸ—ï¸ **System Architecture**

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚        PDFs (n)        â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Document Ingestion   â”‚
                 â”‚ (extraction + chunks) â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚     Embeddings        â”‚
                 â”‚   (vector database)   â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚      Retrieval        â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  LLM Reasoning Layer  â”‚
                 â”‚ (RAG + Memory + CoT)  â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚     Final Answer      â”‚
                 â”‚     + Citations       â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ **Repository Structure**

```
MultiDocRAG/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/         # PDF loading, extraction, chunking
â”‚   â”œâ”€â”€ embeddings/        # Embedding model wrappers
â”‚   â”œâ”€â”€ retrieval/         # Vector search & reranker
â”‚   â”œâ”€â”€ llm/               # Prompting, reasoning, memory, CoT
â”‚   â”œâ”€â”€ evaluation/        # Baseline vs RAG comparisons
â”‚   â”œâ”€â”€ demo/              # Notebook / Streamlit app
â”‚   â””â”€â”€ utils/             # Helper functions
â”‚
â”œâ”€â”€ data/                  # Sample PDFs (if allowed)
â”‚
â”œâ”€â”€ experiments/           # Results, tables, qualitative examples
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE (MIT)
â””â”€â”€ .gitignore
```

---

## ğŸ§ª **Evaluation Overview**

We evaluate on tasks including:

* **Cross-document QA**
* **Comparative analysis**
* **Evidence attribution**
* **Long-context question consistency**

Example evaluation question:

> *â€œHow does the methodology in Paper A differ from Paper B in terms of data assumptions and model constraints?â€*

The system generates:

* Answer with synthesized explanation
* Citations for each referenced document
* Evidence snippets retrieved

---

## â–¶ï¸ **Demo Instructions**

### **1. Install dependencies**

```
pip install -r requirements.txt
```

### **2. Run the demo app**

```
streamlit run app.py
```

### **3. Upload PDFs and start asking questions**

---

## ğŸ¤ **Steps**

* **Document ingestion & retrieval**
* **LLM logic (RAG + reasoning + memory)**
* **System integration & demo**
* **Evaluation + report (baseline vs RAG/memory, experiments, tables, write-up)**

---

## ğŸ“œ **License**

MIT License

---

# ğŸ‰ **MultiDocRAG: Turning Multiple PDFs Into One Coherent Answer**


